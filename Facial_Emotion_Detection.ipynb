{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Facial Emotion Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1s0mCeCVBer2J6vGNEzyoDfLVsokAFMOs",
      "authorship_tag": "ABX9TyMU3gzv9jpvjYC17qUu9aH4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MIlanJP/Facial_emotion_detection__/blob/main/Facial_Emotion_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "534HzJjBBVSx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Required Libraries\n"
      ],
      "metadata": {
        "id": "qVzir4t4BNYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries and dependencies\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as tfl\n",
        "import os \n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision as tv\n",
        "from torchvision import transforms "
      ],
      "metadata": {
        "id": "HQ18eK-U-GF9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OeQHuLCZBTq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "sGjBFvy1B6Op"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading the dataset\n",
        "!gdown --id 1kdAI0wrR_bTBs-6p/bKB6giz-JcNaTY-s\n",
        "\n",
        "# Unzipping the files\n",
        "!unzip '/content/drive/MyDrive/archive.zip'"
      ],
      "metadata": {
        "id": "PSebK4jkB6si"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining te path of train and test dataset\n",
        "train_dir = '/content/train'\n",
        "test_dir = '/content/test'"
      ],
      "metadata": {
        "id": "4neUQW-4B9M6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Data Augumentation <br>\n",
        "  ### a. Training set <br>\n",
        "  - Image Rotation\n",
        "  - Rescaling\n",
        "  - Shear Image\n",
        "  - Zooming the Image\n",
        "  - Horizontal Flip\n",
        "  - Increasing Brightness\n",
        "\n",
        "\n",
        "  ### b. Testing set\n",
        "   - Rescaling\n",
        "\n",
        "#2.Performing train test split \n",
        "## NOTE keeping the dimensions of the image 48 X 48 pixels (Grayscale)\n",
        "- Train Split 27709\n",
        "- Test Split  7178"
      ],
      "metadata": {
        "id": "LNUSLcdEETuo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating batches of tensor image data with real-time data augmentation.\n",
        "# setting the batch size for mini batch\n",
        "batch = 64\n",
        "# setting the dimensions for image\n",
        "img = (48,48)\n",
        "\n",
        "\n",
        "# Setting the Data Augumentation parameters for training data set \n",
        "train_gen = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=20, rescale=1./255, shear_range=0.1,\n",
        "                                                            zoom_range=0.2, horizontal_flip=True,\n",
        "                                                            \n",
        "                                                            brightness_range=(0.2, 0.8))\n",
        "\n",
        "# Fetching the files from train directory and performing the data augumentation\n",
        "train_data = train_gen.flow_from_directory(train_dir, target_size=img, batch_size=batch, class_mode = \"categorical\",\n",
        "                                           color_mode=\"grayscale\"\n",
        "                                           )\n",
        "# Setting the Data Augumentation parameters for validation data set \n",
        "validation_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Fetching the files from test directory and performing the data augumentation\n",
        "validation_data = validation_gen.flow_from_directory(test_dir, target_size=img, batch_size=batch*2, class_mode='categorical',\n",
        "                                                     color_mode=\"grayscale\"\n",
        "                                                     )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYfTXsHAENX_",
        "outputId": "3ffa5bcf-cd84-446a-e278-89fed5a5101f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 28709 images belonging to 7 classes.\n",
            "Found 7178 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BM8WIcuMFH8i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}